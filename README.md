# train_for_image_recognition
# aim：
画像認識・物体検出モデルの精度および提供品質の向上（pytorchをベースに）

# how to do:
・現行モデルの課題を分析し、類似事例の対応手法を検証して精度向上を図る  
・最新の研究動向やOSS（オープンソースソフトウェア）を取り入れ、モデルの精度・パフォーマンス・再現性・安定性を継続的に改善する  
・実運用を見据えたモデルの設計・評価を行い、お客様の要件に応じた柔軟なカスタマイズを通じて納品品質を高める  

・現行モデルの構成を分解・整理し、初学者でも取り組みやすい単位でドキュメント化  
・精度低下の主な原因とその分析手法をまとめて、再現性のある検証プロセスを共有  
・精度向上の一般的な方法（データ拡張・正則化・ハイパーパラメータ調整など）を一覧化  
・分類タスクにおける流行モデルや設定の活用法を整理  
・物体検出・セグメンテーションモデルの知見を分類タスクへ応用可能な形でまとめる  

# issue:
・ベースモデルの構造（effecientNet B0）  
・短時間に精度高いモデルを学習する方法  
    -hardware上（学習実行環境）での改善  
      ・dataloaderで利用するcpu（コア）の数num_workersを適切に選ぶ。例：lscpuでコア数（24）、16/1socketなので、16に設定した  
      ・pin_memory=Trueに設定した  
        →学習時間を40%短縮できた  
        
  -学習の前処理での改善  
    ・transforms.GaussianBlur(kernel_size=11)→ transforms.RandomApply([transforms.GaussianBlur(kernel_size=11,sigma=(0.1, 2.0))], p=0.5)  
    →学習時間を短縮できた（40%?） 
    
  -学習際のパラメータ調整  
    【1】optimizer（最適化アルゴリズム）の役割  
      ・勾配（gradient）を使って、モデルのパラメータ（重み）を更新する ものです。  
      ・loss.backward() で得られた勾配を基に、optimizer.step() によってパラメータを更新します。この更新に使われるのが「学習率（lr）」です  
      ・代表的な optimizer（PyTorch）
| Name  | feature |
| ------------- | ------------- |
| SGD | 最も基本的。勢い（momentum）を加えることで滑らかに進む  |
| Adam | 自動でlrを調整する要素あり（モーメントベース）。安定かつ速い  |
| RMSprop | 平均二乗勾配を使う。RNNでよく使われた  |
| Adagrad, AdamW など | 	特殊な性質を持つ学習向けにチューニングされている |  

    【2】scheduler（学習率スケジューラ）の役割  
    ・optimizerに設定された「学習率（lr）」を、トレーニング中に動的に調整する仕組み  
    ・学習初期：大きな学習率で速く学習  
      学習後期：小さな学習率で細かく調整（収束）  
      停滞：Plateauに入ったら lr を下げて再調整  
      一定周期で上げ下げ：脱局所最適を狙う
    
    【3】optimizer と scheduler の関係  
   | optimizer  | scheduler |
| ------------- | ------------- |
| モデルのパラメータを 更新する | その更新に使う「学習率（lr）」を 調整する  |
| optimizer.step() で重み更新 | scheduler.step() で lr を更新  |
| lr の初期値を持つ | その初期値から調整していく  |  

関係図イメージ：  
```text
          ┌─────────────┐
          │   scheduler │  ← 学習の進み具合に応じて
          └────┬────────┘
               ↓ lr を更新
          ┌────┴─────┐
          │ optimizer│  ← 勾配を使って重み更新
          └────┬─────┘
               ↓
          ┌────┴──────┐
          │  model    │ ← 重み更新される
          └───────────┘
```
  -学習際のパラメータの解凍（fine-tuning)  
  ・EfficientNet（特にB0）の構造  
  | `features.i` | 層の構成                | 出力サイズ (入力224×224想定) | 抽出する特徴               | 解説                       |
| ------------ | ------------------- | ------------------- | -------------------- | ------------------------ |
| `features.0` | Conv3x3, stride=2   | 112×112             | **非常に低レベル**（エッジ、斑点）  | 最初の画像スキャン的処理（画像→特徴）      |
| `features.1` | MBConv1, k3x3, s=1  | 112×112             | 細かい模様、色              | channel数増やさず深さだけ追加       |
| `features.2` | MBConv6, k3x3, s=2  | 56×56               | 色の変化、局所パターン          | stride=2で空間解像度を半減        |
| `features.3` | MBConv6, k5x5, s=2  | 28×28               | 小さいパーツ、構成            | receptive field（受容野）が拡大  |
| `features.4` | MBConv6, k3x3, s=1  | 28×28               | シャリ＋ネタの相関            | 構造的特徴がより強くなる             |
| `features.5` | MBConv6, k5x5, s=2  | 14×14               | シャリ・ネタの組み合わせ         | 空間的にやや抽象的な関係性に注目         |
| `features.6` | MBConv6, k5x5, s=1  | 14×14               | ネタの種類（例：イカvsエビ）      | 空間解像度を維持しつつ表現力拡張         |
| `features.7` | MBConv6, k3x3, s=1  | 14×14               | クラス識別的な構造            | 形・輪郭など意味に近い特徴            |
| `features.8` | Conv1x1 → AvgPool2D | 7×7 → 1×1           | **最も抽象的**（クラス予測前の特徴） | classifierに渡される最後の特徴ベクトル |  

・観察ポイント（段階的fine-tuningで使える）  
🔸 features.0〜2：
画像の初期処理＋基本的な模様や色を捉える  
再利用性が非常に高く、ImageNetで学習済の重みがそのまま有効  
→ 最も凍結すべき層  

🔸 features.3〜6：  
中レベル：シャリとネタの配置、形状などを捉える  
類似クラス（まぐろ vs 中トロなど）の識別に貢献  
→ 中盤で解凍  

🔸 features.7〜8：  
最もクラス識別に近い層  
ここを寿司用に微調整することで精度が上がる  
→ 最初に解凍する層  


